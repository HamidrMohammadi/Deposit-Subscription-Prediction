# -*- coding: utf-8 -*-
"""Bank.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hRxg7_mPwlMcElPkv5nIrXgwIVPkS8ZM

## Ø¹Ù†ÙˆØ§Ù†: Ø§Ø´ØªØ±Ø§Ú© Ø³Ù¾Ø±Ø¯Ù‡ Ø¨Ø§Ù†Ú©ÛŒ
## Ø­Ù…ÛŒØ¯Ø±Ø¶Ø§ Ù…Ø­Ù…Ø¯ÛŒ
Ù‡Ø¯Ù: Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ù…Ø¯Ù„ Ù¾ÛŒØ´ Ø¨ÛŒÙ†ÛŒ Ú©Ù†Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø·Ø¨Ù‚Ù‡ Ø¨Ù†Ø¯ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø± Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ø¨Ø§Ù†Ú©ÛŒ Ù…Ø´ØªØ±Ú© Ù…ÛŒ Ø´ÙˆÙ†Ø¯ ÛŒØ§ Ø®ÛŒØ±ØŸ
ØªÙˆØ¶ÛŒØ­Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø¬Ø²Ø¡ Ù…ØªÙ† Ù‡Ø§ÛŒ Ø¯Ø§Ù‡Ù„ Ù¾Ù„Ø§Øª Ù‡Ø§(Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø´Ú©Ù„ Ù†ÙˆØ´ØªØ§Ø±ÛŒ)

Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª : 
1. Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ù†ÙˆØ¹ÛŒ Ø­Ø³Ø§Ø¨ Ø³Ù¾Ø±Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± ÛŒÚ© Ù…ÙˆØ³Ø³Ù‡ Ù…Ø§Ù„ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…ÛŒ Ø´ÙˆØ¯ Ùˆ Ù¾ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ù…Ø´Ø®ØµÛŒ Ù‚ÙÙ„ Ù…ÛŒ Ø´ÙˆØ¯.                                                        
2. Ø¨Ù‡ Ø·ÙˆØ± Ø®Ù„Ø§ØµÙ‡ Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ø³Ù¾Ø±Ø¯Ù‡ Ø§ÛŒ Ø§Ø³Øª Ú©Ù‡ ÛŒÚ© Ø¨Ø§Ù†Ú© ÛŒØ§ ÛŒÚ© Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú¯Ø°Ø§Ø± Ù…Ø§Ù„ÛŒ Ø¨Ø§ Ù†Ø±Ø® Ø«Ø§Ø¨Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒ Ú©Ù†Ø¯ Ú©Ù‡ Ù¾ÙˆÙ„ Ø´Ù…Ø§ Ø¯Ø± ÛŒÚ© Ø²Ù…Ø§Ù† Ø®Ø§Øµ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒ Ø´ÙˆØ¯
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("BankeHamidreza.csv")

pd.options.display.max_columns = None
data.head()

data.describe()

data.info()

data.isnull().sum()

"""1. Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø¯Ø§Ø±Ø§ÛŒ 17 ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ 11162 Ù…Ø´ØªØ±ÛŒ Ø§Ø³Øª
2. Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø§Ø±Ø²Ø´ Ù¾ÙˆÚ† Ù†Ø¯Ø§Ø±Ø¯
3. Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ù†ÛŒ ØªÙ‚Ø±ÛŒØ¨Ø§ 41 Ø³Ø§Ù„ Ø§Ø³Øª Ú©Ù…ØªØ±ÛŒÙ†: 18 Ø³Ø§Ù„ Ùˆ Ø­Ø¯Ø§Ú©Ø«Ø±: 95 Ø³Ø§Ù„
4. Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ¹Ø§Ø¯Ù„ 1528.3 Ø§Ø³Øª  (Ú©Ù…ØªØ±ÛŒÙ†: -6847 Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø­Ø¯Ø§Ú©Ø«Ø±: 81204)
"""

sns.countplot(x = 'deposit',data = data)
plt.title("Distribution of Term Deposit count")

def bar_plot_basic(var,data):
    sns.countplot(x = var,data = data)
    plt.xlabel(var)
    plt.title("Distribution of {}".format(var))

plt.figure(figsize = [12,12])
plt.subplot(221)
bar_plot_basic('marital',data)

plt.subplot(222)
bar_plot_basic('default',data)

plt.subplot(223)
bar_plot_basic('poutcome',data)

plt.subplot(224)
bar_plot_basic('contact',data)

plt.figure(figsize = [10,18])

plt.subplot(311)
sns.countplot(y = 'job',data = data)
plt.title("Distribution of Job")

plt.subplot(312)
sns.countplot(y = 'education',data = data)
plt.title("Distribution of Education")

plt.subplot(313)
sns.countplot(y = 'month',data = data)
plt.title("Distribution of Month")

"""Ù…Ø´Ø§Ù‡Ø¯Ø§Øª :
1. Ø­Ø¯ÙˆØ¯ 5300 Ù…Ø´ØªØ±ÛŒ Ø¨Ø§ ' Ø¨Ù„Ù‡ ' Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ 5800 Ù…Ø´ØªØ±ÛŒ Ø¨Ø§ 'Ù†Ù‡' Ø¨Ø±Ø§ÛŒ Ø§Ø´ØªØ±Ø§Ú© Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.
2. Ø¨ÛŒØ´ Ø§Ø² 50 Ø¯Ø±ØµØ¯ Ø§Ø² Ù…Ø´ØªØ±ÛŒØ§Ù† Ù…ØªØ§Ù‡Ù„ Ù‡Ø³ØªÙ†Ø¯
3. Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§ÙØ±Ø§Ø¯ Ø¨Ù‡ Ø¬Ø§ÛŒ ØªÙ„ÙÙ† ØªÙ…Ø§Ø³ ØªÙ„ÙÙ† Ù‡Ù…Ø±Ø§Ù‡ Ø¯Ø§Ø±Ù†Ø¯
4. Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ù…Ø´ØªØ±ÛŒØ§Ù† Ù…Ø¯ÛŒØ±, ÛŒÙ‚Ù‡ Ø¢Ø¨ÛŒ(Ú©Ø§Ø±Ú¯Ø±) Ùˆ ØªÚ©Ù†Ø³ÛŒÙ† Ù‡Ø³ØªÙ†Ø¯
"""

def bar_plot(var1,var2,data):
    sns.countplot(x=var1,hue=var2,data = data)
    plt.xlabel(var1)
    plt.title("Distribution of {} by {}".format(var1,var2))

plt.figure(figsize = [15,15])

plt.subplot(221)
bar_plot('month','deposit',data)

plt.subplot(222)
bar_plot('marital','deposit',data)

plt.subplot(223)
bar_plot('contact','deposit',data)

plt.subplot(224)
bar_plot('poutcome','deposit',data)

plt.figure(figsize = [18,14])

plt.subplot(211)
sns.countplot(x = 'education',hue = 'deposit',data = data)

plt.subplot(212)
sns.countplot(x = 'job',hue = 'deposit',data= data)

"""ØªØ¨Ø¯ÛŒÙ„ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙ‡ Ø§ÛŒ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨ Ù‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ

Ù…Ø´Ø§Ù‡Ø¯Ø§Øª :
1. Ø­Ø¯Ø§Ú©Ø«Ø± Ùˆ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ø¯Ø± Ù…Ø§Ù‡ Ù…Ù‡ Ù‡Ø³ØªÙ†Ø¯ (ÙˆØ§Ø¶Ø­ Ø§Ø³Øª Ú©Ù‡ ØªÙ‚Ø±ÛŒØ¨Ø§ 25 Ø¯Ø±ØµØ¯ Ø§Ø² Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ù…Ø§Ù‡ Ù…Ù‡ Ù‡Ø³ØªÙ†Ø¯)
2. Ø­Ø¯ÙˆØ¯ 2700 Ù…Ø´ØªØ±ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø§Ø²Ø¯ÙˆØ§Ø¬ Ú©Ø±Ø¯Ù‡ Ø§Ù†Ø¯ Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ù…Ø´ØªØ±Ú© Ø¯Ø§Ø±Ù†Ø¯
3. Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ ØªÙ…Ø§Ø³ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªÙ„ÙÙ† Ù‡Ù…Ø±Ø§Ù‡ Ø´Ø§Ù†Ø³ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø´ØªØ±Ø§Ú© Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ø¯Ø§Ø±Ù†Ø¯
4. Ù…Ø´ØªØ±ÛŒØ§Ù†ÛŒ Ú©Ù‡ Ù…Ø¯ÛŒØ± Ù‡Ø³ØªÙ†Ø¯, ØªÚ©Ù†Ø³ÛŒÙ†, ÛŒÙ‚Ù‡ Ø¢Ø¨ÛŒ Ø´Ø§Ù†Ø³ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø§Ø² Ø§Ø´ØªØ±Ø§Ú© Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª
"""

# Correlation before converting Categorical variables
corr = data.corr()

sns.heatmap(corr,annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})
fig=plt.gcf()
fig.set_size_inches(12,12)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data.job = le.fit_transform(data.job)
data.education = le.fit_transform(data.education)
data.marital = le.fit_transform(data.marital)
data.default = le.fit_transform(data.default)
data.housing = le.fit_transform(data.housing)
data.loan = le.fit_transform(data.loan)
data.contact = le.fit_transform(data.contact)
data.month = le.fit_transform(data.month)
data.poutcome = le.fit_transform(data.poutcome)
data.deposit = le.fit_transform(data.deposit)
data.loan = le.fit_transform(data.loan)
data.contact = le.fit_transform(data.contact)
data.month = le.fit_transform(data.month)

data["pdays"].replace(-1,int(0),inplace=True)

corr = data.corr()

sns.heatmap(corr,annot=True,square = True,cmap='RdYlGn')
fig=plt.gcf()
fig.set_size_inches(20,20)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()

#Separating X & Y
x=data.drop(columns = ["deposit"])
y=data["deposit"]

"""Ù…Ù‚ÛŒØ§Ø³ Ø¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ØªØ±"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=sc.fit_transform(x)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 0)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score,recall_score,roc_auc_score
from sklearn.model_selection import cross_val_score

"""### Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©"""

LR = LogisticRegression()
lr = LR.fit(X_train,y_train)
y_pred = LR.predict(X_test)
LR_Score = accuracy_score(y_pred,y_test)
print("Accuracy Using LR : ", accuracy_score(y_pred,y_test)*100)
print("Recall score : " ,recall_score(y_pred,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred,y_test) * 100)

lr_acc = cross_val_score(lr, X_train, y_train, cv=3, scoring='accuracy')
print(lr_acc)
CV_LR_score = lr_acc.mean()
print("CV Score using LR : ",CV_LR_score)

"""### Support Vector Machines
###Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù‡Ø§ÛŒ Ø¨Ø±Ø¯Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ
"""

SVM = SVC(kernel='rbf',C =1) 

svm = SVM.fit(X_train,y_train)
y_pred_svm = SVM.predict(X_test)
SVM_Score = accuracy_score(y_pred_svm,y_test)

print("Accuracy Using SVM : ", accuracy_score(y_pred_svm,y_test)*100)
print("Recall score : " ,recall_score(y_pred_svm,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_svm,y_test) * 100)

"""### K Nearest Neighbours Ù†Ø²Ø¯ÛŒÚ©ØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÚ¯Ø§Ù†"""

KNN = KNeighborsClassifier()

KNN.fit(X_train,y_train)
y_pred_knn = KNN.predict(X_test)
KNN_Score = accuracy_score(y_pred_knn,y_test)

print("Accuracy Using KNN : ", accuracy_score(y_pred_knn,y_test)*100)
print("Recall score : " ,recall_score(y_pred_knn,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_knn,y_test) * 100)

"""### Random Forest Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒğŸ˜„(Ø±Ù†Ø¯ÙˆÙ… ÙØ§Ø³Øª)"""

RF= RandomForestClassifier(random_state=0)
from sklearn.model_selection import GridSearchCV
pg_rf={'n_estimators': [100,200,400,500],'max_depth': [20,40,50,60]}
gs_rf=GridSearchCV(estimator= RF,
               param_grid= pg_rf,
               scoring='accuracy',
               cv=2)

gs_rf_scores = cross_val_score(gs_rf, X=X_train, y=y_train, cv=5,scoring='accuracy', n_jobs=-1)
gs_rf.fit(X_train, y_train)
gs_rf_best=gs_rf.best_estimator_
gs_rf_best.fit(X_train, y_train)
y_pred_RF = gs_rf_best.predict(X_test)

RF_Score = gs_rf_scores.mean()
print("Cross Validation Avg Accuracy Using RF : ", gs_rf_scores.mean()*100)
print("Accuracy Using best RF : ", gs_rf_scores.mean()*100)
print("Recall score : " ,recall_score(y_pred_RF,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_RF,y_test) * 100)

importances = gs_rf_best.feature_importances_
importances

feature_names = x.columns

for name, importance in zip(feature_names, gs_rf_best.feature_importances_):
        print(name, "=", importance)

# Important Features using Random Forest
sns.barplot(gs_rf_best.feature_importances_,feature_names)
#feat_importances = pd.Series(gs_rf_best.feature_importances_, index=feature_names)

"""### XGBoost Ø§ÛŒÚ©Ø³ Ø¬ÛŒ Ø¨ÙˆØ³Øª"""

import xgboost
xgb = xgboost.XGBClassifier(n_estimators=200, learning_rate=0.08, gamma=0, subsample=0.75,
                           colsample_bytree=1, max_depth=7)
xgb.fit(X_train,y_train)
y_pred_XGB = xgb.predict(X_test)
XGB_Score = accuracy_score(y_pred_XGB,y_test)

print("Accuracy Using SVM : ", accuracy_score(y_pred_XGB,y_test)*100)
print("Recall score : " ,recall_score(y_pred_XGB,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_XGB,y_test) * 100)

sns.barplot(xgb.feature_importances_,feature_names)

"""### Ù‡Ù…Ù‡ Ù†ØªØ§ÛŒØ¬:ğŸ‘ğŸ™‚ğŸ™ƒ"""

Results = pd.DataFrame({'Model': ['Logistic Regression','SVM','KNN','Random Forest','XGBoost'],
                        'Accuracy Score' : [CV_LR_score,SVM_Score,KNN_Score,RF_Score,XGB_Score]})

Final_Results = Results.sort_values(by = 'Accuracy Score', ascending=False)
Final_Results = Final_Results.set_index('Model')
print(Final_Results)

"""Ø§Ø² Ø¨Ø§Ù„Ø§ Ù†ØªÛŒØ¬Ù‡ Ù…ÛŒ Ú¯ÛŒØ±ÛŒÙ… Ú©Ù‡
1. Ù…Ø¯Ù„ Ù‡Ø§ÛŒ Ø§ÛŒÚ©Ø³ Ø¬ÛŒ Ø¨ÙˆØ³Øª Ùˆ Ø±Ù†Ø¯ÙˆÙ… ÙØ§Ø±Ø³Øª Ø¯Ù‚Øª Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ù†Ø¯
2. Ù…Ø¯Øª Ø²Ù…Ø§Ù†ØŒ Ù…Ø³Ú©Ù†ØŒ ØªÙ…Ø§Ø³ØŒ Ù†ØªÛŒØ¬Ù‡ØŒ ØªØ¹Ø§Ø¯Ù„ Ù…Ù‡Ù… ØªØ±ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒ Ù‡Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§Ø´ØªØ±Ø§Ú© Ø³Ù¾Ø±Ø¯Ù‡ Ù…Ø¯Øª Ø¯Ø§Ø± Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯.


"""