# -*- coding: utf-8 -*-
"""Bank.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hRxg7_mPwlMcElPkv5nIrXgwIVPkS8ZM

## عنوان: اشتراک سپرده بانکی
## حمیدرضا محمدی
هدف: ایجاد یک مدل پیش بینی کننده برای طبقه بندی اینکه مشتریان در سپرده مدت بانکی مشترک می شوند یا خیر؟
توضیحات فارسی به جزء متن های داهل پلات ها(به دلیل مشکل نوشتاری)

سپرده مدت : 
1. سپرده مدت نوعی حساب سپرده است که در یک موسسه مالی نگهداری می شود و پول برای مدت زمان مشخصی قفل می شود.                                                        
2. به طور خلاصه سپرده مدت سپرده ای است که یک بانک یا یک سرمایه گذار مالی با نرخ ثابت پیشنهاد می کند که پول شما در یک زمان خاص بازگردانده می شود
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("BankeHamidreza.csv")

pd.options.display.max_columns = None
data.head()

data.describe()

data.info()

data.isnull().sum()

"""1. داده ها دارای 17 ویژگی با 11162 مشتری است
2. داده ها ارزش پوچ ندارد
3. میانگین سنی تقریبا 41 سال است کمترین: 18 سال و حداکثر: 95 سال
4. میانگین تعادل 1528.3 است  (کمترین: -6847 قدیمی و حداکثر: 81204)
"""

sns.countplot(x = 'deposit',data = data)
plt.title("Distribution of Term Deposit count")

def bar_plot_basic(var,data):
    sns.countplot(x = var,data = data)
    plt.xlabel(var)
    plt.title("Distribution of {}".format(var))

plt.figure(figsize = [12,12])
plt.subplot(221)
bar_plot_basic('marital',data)

plt.subplot(222)
bar_plot_basic('default',data)

plt.subplot(223)
bar_plot_basic('poutcome',data)

plt.subplot(224)
bar_plot_basic('contact',data)

plt.figure(figsize = [10,18])

plt.subplot(311)
sns.countplot(y = 'job',data = data)
plt.title("Distribution of Job")

plt.subplot(312)
sns.countplot(y = 'education',data = data)
plt.title("Distribution of Education")

plt.subplot(313)
sns.countplot(y = 'month',data = data)
plt.title("Distribution of Month")

"""مشاهدات :
1. حدود 5300 مشتری با ' بله ' در حالی که 5800 مشتری با 'نه' برای اشتراک سپرده مدت وجود دارد.
2. بیش از 50 درصد از مشتریان متاهل هستند
3. حداکثر تعداد افراد به جای تلفن تماس تلفن همراه دارند
4. بسیاری از مشتریان مدیر, یقه آبی(کارگر) و تکنسین هستند
"""

def bar_plot(var1,var2,data):
    sns.countplot(x=var1,hue=var2,data = data)
    plt.xlabel(var1)
    plt.title("Distribution of {} by {}".format(var1,var2))

plt.figure(figsize = [15,15])

plt.subplot(221)
bar_plot('month','deposit',data)

plt.subplot(222)
bar_plot('marital','deposit',data)

plt.subplot(223)
bar_plot('contact','deposit',data)

plt.subplot(224)
bar_plot('poutcome','deposit',data)

plt.figure(figsize = [18,14])

plt.subplot(211)
sns.countplot(x = 'education',hue = 'deposit',data = data)

plt.subplot(212)
sns.countplot(x = 'job',hue = 'deposit',data= data)

"""تبدیل متغیرهای دسته ای به قالب های عددی

مشاهدات :
1. حداکثر و حداقل تعداد مشتریان با سپرده مدت در ماه مه هستند (واضح است که تقریبا 25 درصد از مشتریان از ماه مه هستند)
2. حدود 2700 مشتری وجود دارد که ازدواج کرده اند و همچنین سپرده مدت مشترک دارند
3. مشتریان با تماس از طریق تلفن همراه شانس بیشتری برای اشتراک سپرده مدت دارند
4. مشتریانی که مدیر هستند, تکنسین, یقه آبی شانس بالایی از اشتراک سپرده مدت
"""

# Correlation before converting Categorical variables
corr = data.corr()

sns.heatmap(corr,annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})
fig=plt.gcf()
fig.set_size_inches(12,12)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data.job = le.fit_transform(data.job)
data.education = le.fit_transform(data.education)
data.marital = le.fit_transform(data.marital)
data.default = le.fit_transform(data.default)
data.housing = le.fit_transform(data.housing)
data.loan = le.fit_transform(data.loan)
data.contact = le.fit_transform(data.contact)
data.month = le.fit_transform(data.month)
data.poutcome = le.fit_transform(data.poutcome)
data.deposit = le.fit_transform(data.deposit)
data.loan = le.fit_transform(data.loan)
data.contact = le.fit_transform(data.contact)
data.month = le.fit_transform(data.month)

data["pdays"].replace(-1,int(0),inplace=True)

corr = data.corr()

sns.heatmap(corr,annot=True,square = True,cmap='RdYlGn')
fig=plt.gcf()
fig.set_size_inches(20,20)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()

#Separating X & Y
x=data.drop(columns = ["deposit"])
y=data["deposit"]

"""مقیاس بندی داده ها برای نتایج بهتر"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=sc.fit_transform(x)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 0)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score,recall_score,roc_auc_score
from sklearn.model_selection import cross_val_score

"""### رگرسیون لجستیک"""

LR = LogisticRegression()
lr = LR.fit(X_train,y_train)
y_pred = LR.predict(X_test)
LR_Score = accuracy_score(y_pred,y_test)
print("Accuracy Using LR : ", accuracy_score(y_pred,y_test)*100)
print("Recall score : " ,recall_score(y_pred,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred,y_test) * 100)

lr_acc = cross_val_score(lr, X_train, y_train, cv=3, scoring='accuracy')
print(lr_acc)
CV_LR_score = lr_acc.mean()
print("CV Score using LR : ",CV_LR_score)

"""### Support Vector Machines
###دستگاه های بردار پشتیبانی
"""

SVM = SVC(kernel='rbf',C =1) 

svm = SVM.fit(X_train,y_train)
y_pred_svm = SVM.predict(X_test)
SVM_Score = accuracy_score(y_pred_svm,y_test)

print("Accuracy Using SVM : ", accuracy_score(y_pred_svm,y_test)*100)
print("Recall score : " ,recall_score(y_pred_svm,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_svm,y_test) * 100)

"""### K Nearest Neighbours نزدیکترین همسایگان"""

KNN = KNeighborsClassifier()

KNN.fit(X_train,y_train)
y_pred_knn = KNN.predict(X_test)
KNN_Score = accuracy_score(y_pred_knn,y_test)

print("Accuracy Using KNN : ", accuracy_score(y_pred_knn,y_test)*100)
print("Recall score : " ,recall_score(y_pred_knn,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_knn,y_test) * 100)

"""### Random Forest جنگل تصادفی😄(رندوم فاست)"""

RF= RandomForestClassifier(random_state=0)
from sklearn.model_selection import GridSearchCV
pg_rf={'n_estimators': [100,200,400,500],'max_depth': [20,40,50,60]}
gs_rf=GridSearchCV(estimator= RF,
               param_grid= pg_rf,
               scoring='accuracy',
               cv=2)

gs_rf_scores = cross_val_score(gs_rf, X=X_train, y=y_train, cv=5,scoring='accuracy', n_jobs=-1)
gs_rf.fit(X_train, y_train)
gs_rf_best=gs_rf.best_estimator_
gs_rf_best.fit(X_train, y_train)
y_pred_RF = gs_rf_best.predict(X_test)

RF_Score = gs_rf_scores.mean()
print("Cross Validation Avg Accuracy Using RF : ", gs_rf_scores.mean()*100)
print("Accuracy Using best RF : ", gs_rf_scores.mean()*100)
print("Recall score : " ,recall_score(y_pred_RF,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_RF,y_test) * 100)

importances = gs_rf_best.feature_importances_
importances

feature_names = x.columns

for name, importance in zip(feature_names, gs_rf_best.feature_importances_):
        print(name, "=", importance)

# Important Features using Random Forest
sns.barplot(gs_rf_best.feature_importances_,feature_names)
#feat_importances = pd.Series(gs_rf_best.feature_importances_, index=feature_names)

"""### XGBoost ایکس جی بوست"""

import xgboost
xgb = xgboost.XGBClassifier(n_estimators=200, learning_rate=0.08, gamma=0, subsample=0.75,
                           colsample_bytree=1, max_depth=7)
xgb.fit(X_train,y_train)
y_pred_XGB = xgb.predict(X_test)
XGB_Score = accuracy_score(y_pred_XGB,y_test)

print("Accuracy Using SVM : ", accuracy_score(y_pred_XGB,y_test)*100)
print("Recall score : " ,recall_score(y_pred_XGB,y_test) * 100)
print("ROC score : ", roc_auc_score(y_pred_XGB,y_test) * 100)

sns.barplot(xgb.feature_importances_,feature_names)

"""### همه نتایج:👍🙂🙃"""

Results = pd.DataFrame({'Model': ['Logistic Regression','SVM','KNN','Random Forest','XGBoost'],
                        'Accuracy Score' : [CV_LR_score,SVM_Score,KNN_Score,RF_Score,XGB_Score]})

Final_Results = Results.sort_values(by = 'Accuracy Score', ascending=False)
Final_Results = Final_Results.set_index('Model')
print(Final_Results)

"""از بالا نتیجه می گیریم که
1. مدل های ایکس جی بوست و رندوم فارست دقت بهتری داده اند
2. مدت زمان، مسکن، تماس، نتیجه، تعادل مهم ترین ویژگی های مشتریان است که در هنگام اشتراک سپرده مدت دار باید در نظر گرفته شود.


"""